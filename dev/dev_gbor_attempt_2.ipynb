{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "a085b863-b0bb-4f4e-a65c-6be607be1421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.utils import check_X_y\n",
    "from sklearn.base import clone\n",
    "\n",
    "class BoostedOrdinal(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, base_learner = DecisionTreeRegressor(), max_iter=100, lr_g = 1.0, lr_theta = 1e-2):\n",
    "        self.base_learner = base_learner\n",
    "        self.max_iter = max_iter\n",
    "        self.lr_g = lr_g\n",
    "        self.lr_theta = lr_theta\n",
    "\n",
    "    def predict(self, X):\n",
    "        check_array(X)\n",
    "        return np.array([learner.predict(X) + self.path['intercept'][p] for p, learner in enumerate(self.path['learner'])])\n",
    "    \n",
    "    def _probabilities(g, theta, y = None):\n",
    "        probs = np.array([np.diff(norm.cdf(BoostedOrdinal._pad_thresholds(theta - x))) for x in g])\n",
    "\n",
    "        if y is None:\n",
    "            return probs\n",
    "        \n",
    "        loglike = sum([np.log(probs[n, yn]) for n, yn in enumerate(y)])\n",
    "        return probs, loglike\n",
    "    \n",
    "    def _check_loss_change(loss):\n",
    "        x = np.diff(loss)\n",
    "        return (x[::2], x[1::2]) # (g, theta)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y)\n",
    "        ylist = BoostedOrdinal._validate_ordinal(y)\n",
    "\n",
    "        g_init, theta_init = BoostedOrdinal._initialize(y)\n",
    "        loss_init = BoostedOrdinal._loss_function(X, y, g_init, theta_init)\n",
    "\n",
    "        g, theta = g_init, theta_init\n",
    "        loss_all = []\n",
    "        learner_all = []\n",
    "        intercept_all = []\n",
    "        g_all = []\n",
    "        theta_all = []\n",
    "\n",
    "        loss_all.append(loss_init)\n",
    "        g_all.append(g_init)\n",
    "        theta_all.append(theta_init)\n",
    "\n",
    "        for p in range(self.max_iter):\n",
    "            \n",
    "            # update regression function\n",
    "            dg = BoostedOrdinal._derivative_g(X, y, theta, g)\n",
    "            weak_learner, h, intercept = BoostedOrdinal._fit_weak_learner(X, -dg, clone(self.base_learner))\n",
    "            g = BoostedOrdinal._update_g(g, h, lr = self.lr_g)\n",
    "            \n",
    "            # update loss\n",
    "            loss_all.append(\n",
    "                BoostedOrdinal._loss_function(X, y, g, theta)\n",
    "            )\n",
    "            \n",
    "            # update threshold vector\n",
    "            dtheta = BoostedOrdinal._derivative_threshold(X, ylist, theta, g)\n",
    "            theta = BoostedOrdinal._update_thresh(theta, dtheta, lr = self.lr_theta)\n",
    "\n",
    "            # update loss\n",
    "            loss_all.append(\n",
    "                BoostedOrdinal._loss_function(X, y, g, theta)\n",
    "            )\n",
    "            \n",
    "            learner_all.append(weak_learner)\n",
    "            intercept_all.append(intercept)\n",
    "            g_all.append(g)\n",
    "            theta_all.append(theta)\n",
    "\n",
    "        self.n_iter = self.max_iter # in future, we may exit before reaching max_iter\n",
    "        self.final = {'g': g, 'theta': theta, 'loss': loss_all[-1]}\n",
    "        self.path = {'g': np.array(g_all), 'theta': np.array(theta_all), 'loss': np.array(loss_all), 'learner': learner_all, 'intercept': np.array(intercept_all)}\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _validate_ordinal(arr):\n",
    "        \"\"\"\n",
    "        Check if the unique values in a numpy integer vector are 0, 1, ..., M with M >= 2.\n",
    "    \n",
    "        Parameters:\n",
    "        arr (numpy.ndarray): Input numpy integer vector.\n",
    "    \n",
    "        Returns:\n",
    "        bool: True if unique values are 0, 1, ..., M with M >= 2, False otherwise.\n",
    "        \"\"\"\n",
    "        if not isinstance(arr, np.ndarray):\n",
    "            raise ValueError(\"Input must be a numpy array\")\n",
    "        if arr.dtype.kind not in {'i', 'u'}:\n",
    "            raise ValueError(\"Input array must contain integers\")\n",
    "    \n",
    "        unique_values = np.unique(arr)\n",
    "        \n",
    "        if unique_values[0] != 0:\n",
    "            return []\n",
    "        \n",
    "        M = unique_values[-1]\n",
    "\n",
    "        if M < 2:\n",
    "            return []\n",
    "        \n",
    "        expected_values = np.arange(M + 1)\n",
    "\n",
    "        if np.array_equal(unique_values, expected_values):\n",
    "            #return M + 1\n",
    "            return [np.where(arr == m) for m in unique_values]\n",
    "        else:\n",
    "            return []\n",
    "    \n",
    "    def _initialize(y):\n",
    "        return (BoostedOrdinal._initialize_g(y), BoostedOrdinal._initialize_thresholds(y))\n",
    "    \n",
    "    def _initialize_g(y):\n",
    "        return np.zeros(y.size)\n",
    "    \n",
    "    def _initialize_thresholds(y):\n",
    "        # Calculate the initial threshold vector\n",
    "        n_samples = len(y)\n",
    "        n_class = np.max(y) + 1\n",
    "        P = np.array([np.sum(y == i) for i in range(n_class)]) / n_samples\n",
    "        return norm.ppf(np.cumsum(P[:-1]))\n",
    "    \n",
    "    def _pad_thresholds(theta):\n",
    "        return np.insert(theta, [0, theta.size], [-np.inf, np.inf])\n",
    "    \n",
    "    def _derivative_threshold(X, ylist, thresh, g):\n",
    "        thresh_padded = BoostedOrdinal._pad_thresholds(thresh)\n",
    "        M = len(thresh)\n",
    "        ret = []\n",
    "        for m in range(M):\n",
    "            S_m = ylist[m]\n",
    "            S_mp1 = ylist[m+1]\n",
    "            v1 = np.sum(norm.pdf(thresh_padded[m+1] - g[S_m]) / (norm.cdf(thresh_padded[m+1] - g[S_m]) - norm.cdf(thresh_padded[m] - g[S_m])))\n",
    "            v2 = np.sum(norm.pdf(thresh_padded[m+1] - g[S_mp1]) / (norm.cdf(thresh_padded[m+2] - g[S_mp1]) - norm.cdf(thresh_padded[m+1] - g[S_mp1])))\n",
    "            ret.append(-v1 + v2)\n",
    "        return np.array(ret)\n",
    "\n",
    "    def _derivative_g(X, y, thresh, g):\n",
    "        thresh_padded = BoostedOrdinal._pad_thresholds(thresh)\n",
    "        ret = (norm.pdf(thresh_padded[y+1] - g) - norm.pdf(thresh_padded[y] - g)) / (norm.cdf(thresh_padded[y+1] - g) - norm.cdf(thresh_padded[y] - g))\n",
    "        return ret\n",
    "\n",
    "    def _fit_weak_learner(X, pseudo_resids, learner):\n",
    "        learner.fit(X, pseudo_resids)\n",
    "        pred = learner.predict(X)\n",
    "        intercept = -np.mean(pred) # we could also perform intercept adjustment in _update_g but mathematically the effect is the same\n",
    "        return (learner, pred + intercept, intercept)\n",
    "    \n",
    "    # replace with more sophisticated version that performs line search\n",
    "    def _update_g(g, h, lr = 1e-1):\n",
    "        return g + lr * h\n",
    "    \n",
    "    # we need to check if updated thresh is valid (must be sorted) and handle invalid ones\n",
    "    def _update_thresh(thresh, dthresh, lr = 1e-3):\n",
    "        new_thresh = thresh - lr * dthresh\n",
    "        if not np.all(np.diff(new_thresh)):\n",
    "            raise ValueError(\"updated threshold vector invalid (must have strict ascending order)\")\n",
    "        return new_thresh\n",
    "    \n",
    "    # this can be fused with _probabilities, though this is likely more efficient is the goal is only loss and not the prob matrix\n",
    "    def _loss_function(X, y, g, theta):\n",
    "        theta_padded = BoostedOrdinal._pad_thresholds(theta)\n",
    "        return -np.sum(np.log(norm.cdf(theta_padded[y + 1] - g) - norm.cdf(theta_padded[y] - g)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "37da0802-2b07-4502-ba80-c1b53376e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a sample dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=3, n_informative=5, random_state=1)\n",
    "indices = BoostedOrdinal._validate_ordinal(y)\n",
    "#print(len(indices))\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "545ca0b1-9ddb-4b2d-9763-3e804306e72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BoostedOrdinal(max_iter = 10, lr_g = 1e-1, lr_theta = 1e-3, base_learner = DecisionTreeRegressor(max_depth = 3)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "75b00e39-b173-4bb8-8131-7e23f2cd79c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([878.85487184, 853.07589248, 852.9936132 , 830.61493802,\n",
       "       830.53102021, 810.96326189, 810.88391969, 794.58732095,\n",
       "       794.52296859, 778.94443116, 778.87888521, 762.28788039,\n",
       "       762.21386072, 749.49485681, 749.43077129, 735.75591784,\n",
       "       735.68958443, 723.53156407, 723.47251361, 712.69965495,\n",
       "       712.64283255])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.path['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "86e95c9a-8d60-4632-bd60-ad9889f2134c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-712.6428325463814"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ , loglike = BoostedOrdinal._probabilities(model.final['g'], model.final['theta'], y_train)\n",
    "#_ , loglike = BoostedOrdinal._probabilities(model.path['g'][0], model.path['theta'][0], y_train)\n",
    "loglike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "c3df8afc-4891-4f01-a961-4dccad058402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dloss_g, dloss_theta = BoostedOrdinal._check_loss_change(model.path['loss'])\n",
    "np.all(dloss_g < 0), np.all(dloss_theta < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6b8f11bc-85f9-4c20-bf84-a0fcd81d2add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "878.8548718382214"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_indices = BoostedOrdinal._validate_ordinal(y_train)\n",
    "theta_init = BoostedOrdinal._initialize_thresholds(y_train)# + 1\n",
    "g_init = np.zeros(X_train.shape[0])\n",
    "\n",
    "my_loss_init = BoostedOrdinal._loss_function(X_train, y_train, g_init, theta_init)\n",
    "\n",
    "#BoostedOrdinal._derivative_threshold(X_train, my_indices, theta_init, g_init)\n",
    "#my_dthresh = BoostedOrdinal._derivative_threshold(X_train, my_indices, theta_init, g_init)\n",
    "#print(theta_init)\n",
    "#BoostedOrdinal._update_thresh(theta_init, my_dthresh)\n",
    "my_pseudo_resids = -BoostedOrdinal._derivative_g(X_train, y_train, theta_init, g_init)\n",
    "#my_pseudo_resids#[3:5]\n",
    "my_loss_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "86d50848-3082-47df-af55-510689c10520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "706.1121645706666"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "my_weak_learner, my_h = BoostedOrdinal._fit_weak_learner(X_train, my_pseudo_resids, DecisionTreeRegressor(max_depth = 3))\n",
    "my_g = BoostedOrdinal._update_g(g_init, my_h, lr = 1e0)\n",
    "BoostedOrdinal._loss_function(X_train, y_train, g_init + my_g, theta_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "98065f2e-88aa-49fa-b569-004d35974fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "698.6227248850801"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dthresh = BoostedOrdinal._derivative_threshold(X_train, my_indices, theta_init, my_g)\n",
    "my_theta = BoostedOrdinal._update_thresh(theta_init, my_dthresh)\n",
    "BoostedOrdinal._loss_function(X_train, y_train, my_g, my_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1bcf11a0-5d39-4983-b5f1-d98d74b29d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BoostedOrdinal._initialize_g(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "d5abfd45-49df-4a95-86c1-d68a94aa8938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "u = 1\n",
    "if u:\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "4a523d03-af7e-4186-a23f-14efc0d94952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 1, 0, 0, 2, 1, 1, 2, 1, 0, 2, 0, 1,\n",
       "       2, 0, 0, 2, 0, 2, 2, 1, 1, 1, 0, 0, 0, 2, 0, 1, 2, 1, 1, 1, 2, 1,\n",
       "       2, 0, 2, 0, 1, 2, 2, 1, 0, 1, 2, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 1,\n",
       "       2, 2, 0, 0, 0, 1, 0, 0, 2, 2, 2, 1, 2, 2, 2, 0, 2, 0, 1, 0, 1, 2,\n",
       "       0, 1, 0, 1, 1, 1, 0, 2, 1, 2, 1, 0, 0, 2, 0, 0, 1, 0, 1, 2, 2, 0,\n",
       "       0, 2, 0, 2, 1, 2, 0, 0, 2, 0, 1, 1, 1, 0, 2, 0, 0, 1, 1, 1, 2, 1,\n",
       "       2, 1, 0, 1, 0, 1, 1, 2, 1, 2, 1, 2, 2, 1, 0, 0, 2, 1, 1, 0, 1, 2,\n",
       "       1, 2, 1, 1, 1, 2, 0, 1, 2, 0, 0, 2, 0, 2, 2, 0, 2, 2, 1, 2, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 2, 1, 0, 1, 0, 1, 0, 0, 2, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 2, 2, 0, 2, 2, 1, 0, 2, 0, 1, 1, 1, 0, 2, 0, 0, 1,\n",
       "       1, 1, 1, 0, 2, 0, 1, 1, 1, 2, 0, 1, 0, 1, 1, 0, 2, 1, 1, 1, 1, 2,\n",
       "       0, 2, 2, 0, 1, 1, 2, 2, 0, 0, 1, 1, 0, 1, 2, 0, 1, 1, 1, 1, 0, 2,\n",
       "       1, 0, 1, 0, 0, 1, 2, 1, 0, 2, 2, 0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 1,\n",
       "       0, 0, 0, 0, 2, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 2, 0, 0, 0, 0, 1,\n",
       "       2, 2, 1, 2, 1, 1, 2, 1, 0, 2, 0, 1, 2, 2, 2, 0, 2, 2, 1, 1, 1, 1,\n",
       "       2, 1, 0, 1, 2, 2, 0, 1, 1, 0, 1, 2, 0, 2, 1, 0, 1, 2, 1, 1, 0, 0,\n",
       "       0, 1, 1, 2, 2, 0, 2, 1, 2, 1, 0, 1, 1, 2, 2, 0, 2, 2, 0, 2, 1, 0,\n",
       "       0, 1, 0, 0, 1, 2, 0, 2, 1, 2, 2, 2, 0, 1, 2, 2, 1, 1, 2, 0, 2, 2,\n",
       "       2, 2, 1, 0, 2, 1, 2, 0, 2, 2, 0, 1, 0, 2, 2, 0, 1, 0, 0, 1, 2, 0,\n",
       "       2, 2, 2, 1, 2, 0, 2, 2, 2, 0, 0, 1, 2, 1, 0, 2, 1, 2, 2, 2, 2, 1,\n",
       "       2, 1, 2, 1, 1, 2, 0, 0, 0, 2, 0, 0, 0, 1, 2, 1, 1, 0, 1, 2, 2, 2,\n",
       "       0, 2, 0, 1, 2, 0, 2, 2, 2, 0, 2, 0, 0, 0, 1, 0, 0, 0, 1, 2, 1, 1,\n",
       "       1, 0, 2, 2, 1, 2, 1, 2, 1, 0, 2, 0, 2, 0, 1, 2])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09f6f11-53ae-4804-9458-104f3a43222a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
